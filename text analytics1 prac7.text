

!pip install nltk

import nltk
nltk.download('punkt')

from nltk.tokenize import sent_tokenize
text="""Hello Mr.Smith, how are you doing today? The weather is great, and city is awesome. The sky is pinkish-blue.you shouldn't
eat cardboard"""
tokenized_text=sent_tokenize(text)
print(tokenized_text)

from nltk.tokenize import word_tokenize
tokenized_word=word_tokenize(text)
print(tokenized_word)

from nltk.probability import FreqDist
fdist=FreqDist(tokenized_word)
print(fdist)

import matplotlib. pyplot as plt
fdist.plot(30,cumulative=False)
plt.show()

sent="Albert Einstein was born in Ulm, Germany in 1879."
tokens=nltk.word_tokenize(sent)
print(tokens)

nltk.download("averaged_perceptron_tagger")

import nltk
nltk.download('averaged_perceptron_tagger')
nltk.pos_tag(tokens)

nltk.download("stopwords")

from nltk.corpus import stopwords
stop_words=set(stopwords.words("english")) 
print(stop_words)



filtered_sent=[]
for W in tokenized_sent:
    if W not in stop_words:
        filtered_sent.append(W)
print("Tokenized Sentence :",tokenized_sent)
print("Filtered Sentence:",filtered_sent)



from nltk.stem import PorterStemmer
from nltk.tokenize import sent_tokenize,word_tokenize
ps=PorterStemmer()
stemmed_words=[]
for w in filtered_sent:
    stemmed_words.append(ps.stem(w))
print("Filtered Sentence:",filtered_sent)
print("Stemmed Sentence:",stemmed_words)



from nltk.stem.wordnet import WordNetLemmatizer
lem=WordNetLemmatizer
